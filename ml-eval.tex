% resampling
\newcommand{\ntest}{n_{\mathrm{test}}}                              % size of the test set
\newcommand{\ntrain}{n_{\mathrm{train}}}                            % size of the train set
\newcommand{\ntesti}[1][i]{n_{\mathrm{test},#1}}                    % size of the i-th test set
\newcommand{\ntraini}[1][i]{n_{\mathrm{train},#1}}                  % size of the i-th train set
\newcommand{\Jtrain}{J_\mathrm{train}}                              % index vector associated to the train data
\newcommand{\Jtest}{J_\mathrm{test}}                                % index vector associated to the test data
\newcommand{\Jtraini}[1][i]{J_{\mathrm{train},#1}}                  % index vector associated to the i-th train dataset
\newcommand{\Jtesti}[1][i]{J_{\mathrm{test},#1}}                    % index vector associated to the i-th test dataset
\newcommand{\Dtraini}[1][i]{\mathcal{D}_{\text{train},#1}}          % D_train,i, i-th training set
\newcommand{\Dtesti}[1][i]{\mathcal{D}_{\text{test},#1}}            % D_test,i, i-th test set

\newcommand{\JSpace}[1][m]{\{1,\dots,n\}^{#1}}                  % space of train indices of size m_train
\newcommand{\JtrainSpace}{\{1,\dots,n\}^{\ntrain}}                  % space of train indices of size m_train
\newcommand{\JtestSpace}{\{1,\dots,n\}^{\ntest}}                    % space of train indices of size m_test
\newcommand{\yJ}[1][J]{\yv_{#1}}                                    % output vector associated to index J
\newcommand{\yJDef}{\left(y^{(J^{(1)})},\dots,y^{(J^{(m)})}\right)} % def of the output vector associated to index J
\newcommand{\JJ}{\mathcal{J}}                                       % cali-J, set of all splits
\newcommand{\JJset}{\left((\Jtraini[1], \Jtesti[1]),\dots,(\Jtraini[B], \Jtesti[B])\right)}
                                                            % (Jtrain_1,Jtest_1) ...(Jtrain_B,Jtest_B)

% Generalization error
\newcommand{\GE}{\mathrm{GE}}                                             % GE
\newcommand{\GEh}{\widehat{\GE}}                                             % GE-hat 
\newcommand{\GEfull}[1][\ntrain]{\GE(\inducer, \lamv, #1, \rho)}          % GE(I, lam, ?, rho)
\newcommand{\GEhholdout}{\GEh_{\Jtrain, \Jtest}(\inducer, \lamv, |\Jtrain|, \rho)}    % GE-hat_{Jtrain,Jtest} (I, lam, |J|, rho)
\newcommand{\GEhholdouti}[1][i]{\GEh_{\Jtraini[#1], \Jtesti[#1]}(\inducer, \lamv, |\Jtraini[#1]|, \rho)}           
                                                                                     % GE-hat_{Jtrain_i,Jtest_i} (I, lam, |Jtrain_i|, rho)
\newcommand{\GEhlam}{\GEh(\lamv)}                                                 % GE-hat(lam) 
\newcommand{\GEhlamsubIJrho}{\GEh_{\inducer, \JJ, \rho}(\lamv)}                   % GE-hat_I,J,rho(lam) 
\newcommand{\GEhresa}{\GEh(\inducer, \JJ, \rho, \lamv)}                   % GE-hat_I,J,rho(lam) 

\newcommand{\GErhoDef}{\lim_{\ntest\rightarrow\infty} \E \left[ \rho\left(\yv_{\Jtest}, \FJtestftrain\right)\right]}


\newcommand{\agr}{\mathrm{agr}}                       % aggregate function
\newcommand{\GEf}{\GE\left(\fh\right)}                             		% Generalization error of a fitted model
\newcommand{\GEind}{GE_n\left(\inducer_{L, O}\right)}                             		% Generalization error of a fitted model
\newcommand{\GEnf}[1]{GE_n\left(\fh_{#1}\right)}                             % Generalization error GE
\newcommand{\GEhat}{\widehat{\mathrm{GE}}}                                  % Estimated train error
\newcommand{\GED}{\GE{\D}}                                                  % Generalization error GE
\newcommand{\EGEn}{EGE_n}                                                   % Generalization error GE
\newcommand{\EDn}{\E_{|D| = n}}                                             % Generalization error GE

% performance measure
\newcommand{\rhoL}{\rho_L}                 % perf. measure derived from pointwise loss function L
\newcommand{\F}{\boldsymbol{F}}             % matrix of prediction scores
\newcommand{\Fi}[1][i]{\F^{(#1)}}             % i'th row vector of the prediction scores matrix
\newcommand{\FJ}[1][J]{\F_{#1}}             % prediction scores matrix regarding index vector J 
\newcommand{\FJf}{\FJ[J,f]}             % prediction scores matrix regarding index vector J and model f
\newcommand{\FJtestfh}{\FJ[\Jtest, \fh]}      % prediction scores matrix regarding index vector Jtest and model f hat
\newcommand{\FJtestftrain}{\F_{\Jtest,\inducer(\Dtrain, \lamv)}}             % prediction scores matrix regarding index vector Jtest and model f
\newcommand{\FJtestftraini}[1][i]{\F_{\Jtesti[#1],\inducer(\Dtraini[#1], \lamv)}}             % prediction scores matrix regarding i-th index vector Jtest and model f
\newcommand{\FJfDef}{\left(f(\xv^{(J^{(1)})}),\dots, f(\xv^{(J^{(m)})})\right)}                        % def of the prediction scores matrix regarding index vector J and model f
\newcommand{\preimageRho}{\bigcup_{m\in\N}\left(\Yspace^m\times\R^{m\times g}\right)}     % Set of all datasets times the hyperparameter space

% ml - ROC
\newcommand{\np}{n_{+}}                                                     % no. of positive instances
\newcommand{\nn}{n_{-}}                                                     % no. of negative instances
\newcommand{\rn}{\pi_{-}}                                                   % proportion negative instances
\newcommand{\rp}{\pi_{+}}                                                   % proportion negative instances
  % true/false pos/neg:
\newcommand{\tp}{\# \text{TP}}
\newcommand{\fap}{\# \text{FP}} %fp taken for partial derivs
\newcommand{\tn}{\# \text{TN}}
\newcommand{\fan}{\# \text{FN}} 
